# Getting Rich

## Key Notes

### Reproduce Stock Market Direction Random Forests

Paper results are possibly affected by data leakeage. Train data and test data may be overfit.

### Stock Prediction Models

Lots of models in a single repositorty. Working but improperly implemented examples. More than 2K stars.

#### Evolution Strategy Agent

Original version of the agent doesn't split train/test data and works perfectly beacuse using all data. After splitting performance decreased obviously. Original implementation has some problems some are causing negative money, not suitable for bitcoin (using minimum 1 asset) e.g.

### Stock Selection A Framework

Compare different implemented algorithms. Genetic Algorithms Feature selector (filter.npy) should be trained for different data (obviously). Data pipeline is not clear. It uses 244 different indicators.

### Stock Prediction AI

Lots of missing codes & parts exists. Using FFT is problemmatic because it contains future data.

## Possible to use

- Technical indicators
- Long short-term memory (LSTM)
- Convolutional Neural Network (CNN)
- Fourier Transform
- Autoregressive Integrated Moving Average (ARIMA)
- Recurrent Neural Network (RNN)
- Reinforcement learning
- Self-organized Map (SOM)
- U-Net
- Sentiment Analysis
  - Neuro-linguistic programming (NLP)
  - Bidirectional Encoder Representations from Transformers (BERT)
  - MXNet
  - Gluon
- Statistical checks
  - Conditional Heteroskedasticity
  - Multicollinearity
  - Serial correlation
- Feature Engineering
  - eXtreme Gradient Boosting (XGBoost)
- Extracting high-level features with Stacked Autoencoders
  - Activation function - GELU (Gaussian Error)
  - Eigen portfolios
  - Principal Component Analysis (PCA)
  - Deep Unsupervised Learning
  - Anomaly Detection
- Generative Adversarial Network (GAN)
  - Generator
  - Discriminator
  - Metropolis-Hastings GAN (MHGAN)
  - Discriminator Rejection Sampling
  - Wasserstein GAN (WGAN)
- Gated Recurrent Unit (GRU)
- Data quality
- Regularization (or weights penalty)
  - LASSO (L1)
  - Ridge (L2)
- Dropout
- Dense-sparse-dense training
- Early stopping
- Bias
- Variance
- Hyperparameters
  - Hyperparameters optimization
- Reinforcement Learning Theory
- Q-learning
  - Rainbow
  - DQN
  - Double Q Learning
  - Prioritized replay
  - Dueling networks
  - Multi-step learning
  - Distributional RL
  - Noisy Nets
- Policy Optimization
- Proximal Policy Optimization
- Augmented Random Search
- Proximal Policy Optimization (PPO)
- Bayesian optimisation
  - Gaussian process
- Random Forests
